{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrTSsN7kLwEU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install linformer\n",
        "!pip install vit_pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLDm2MOvLwlJ",
        "outputId": "7e2d4d74-5d16-4ffc-9d56-860552d2f139"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linformer\n",
            "  Downloading linformer-0.2.3-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from linformer) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->linformer)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->linformer)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->linformer)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->linformer)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->linformer)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->linformer)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->linformer)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->linformer)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->linformer)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->linformer)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->linformer)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->linformer) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->linformer)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->linformer) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->linformer) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, linformer\n",
            "Successfully installed linformer-0.2.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting vit_pytorch\n",
            "  Downloading vit_pytorch-1.6.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.7.0 (from vit_pytorch)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from vit_pytorch) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from vit_pytorch) (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->vit_pytorch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10->vit_pytorch) (12.5.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->vit_pytorch) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->vit_pytorch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->vit_pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->vit_pytorch) (1.3.0)\n",
            "Installing collected packages: einops, vit_pytorch\n",
            "Successfully installed einops-0.8.0 vit_pytorch-1.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzBEo5s0Lwns",
        "outputId": "a3623880-dc59-4a4c-93f9-d55d869fc8e9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import transforms, datasets\n",
        "from linformer import Linformer\n",
        "from vit_pytorch.efficient import ViT\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Define paths\n",
        "train_dir = '/content/drive/MyDrive/dataset/training'\n",
        "val_dir = '/content/drive/MyDrive/dataset/test'\n",
        "test_dir = '/content/drive/MyDrive/dataset/validation'\n",
        "\n",
        "# Hyperparameters\n",
        "IMG_SIZE = 224  # Example image size\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "patch_size = 16\n",
        "num_classes = 2\n",
        "lr = 0.001\n",
        "gamma = 0.7\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Define transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomResizedCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=transform_train)\n",
        "valid_ds = datasets.ImageFolder(val_dir, transform=transform)\n",
        "test_ds = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "# Function to rebalance dataset\n",
        "def rebalance_dataset(dataset):\n",
        "    class_indices = [np.where(np.array(dataset.targets) == i)[0] for i in range(len(dataset.classes))]\n",
        "    min_class_len = min(len(class_indices[0]), len(class_indices[1]))\n",
        "    balanced_indices = np.concatenate([class_indices[i][:min_class_len] for i in range(len(dataset.classes))])\n",
        "    return torch.utils.data.Subset(dataset, balanced_indices)\n",
        "\n",
        "# Rebalance validation and test sets\n",
        "valid_ds_balanced = rebalance_dataset(valid_ds)\n",
        "test_ds_balanced = rebalance_dataset(test_ds)\n",
        "\n",
        "# DataLoaders with balanced datasets\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "valid_loader = DataLoader(valid_ds_balanced, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds_balanced, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "# Calculate class weights\n",
        "class_counts = np.bincount(train_ds.targets)\n",
        "class_weights = 1. / class_counts\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "\n",
        "# Define loss function with weights\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
        "\n",
        "# Linear Transformer\n",
        "efficient_transformer = Linformer(dim=128, seq_len=(IMG_SIZE // patch_size) ** 2 + 1, depth=12, heads=8, k=64)\n",
        "\n",
        "# Vision Transformer Model\n",
        "model = ViT(\n",
        "    dim=128,\n",
        "    image_size=IMG_SIZE,\n",
        "    patch_size=patch_size,\n",
        "    num_classes=num_classes,\n",
        "    transformer=efficient_transformer,\n",
        "    channels=3\n",
        ").to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    for data, label in tqdm(train_loader):\n",
        "        data, label = data.to(device), label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        acc = (output.argmax(dim=1) == label).float().mean()\n",
        "        epoch_accuracy += acc / len(train_loader)\n",
        "        epoch_loss += loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        epoch_val_accuracy = 0\n",
        "        epoch_val_loss = 0\n",
        "        for data, label in valid_loader:\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            val_output = model(data)\n",
        "            val_loss = criterion(val_output, label)\n",
        "\n",
        "            acc = (val_output.argmax(dim=1) == label).float().mean()\n",
        "            epoch_val_accuracy += acc / len(valid_loader)\n",
        "            epoch_val_loss += val_loss / len(valid_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.4f}, Val Loss: {epoch_val_loss:.4f}, Val Accuracy: {epoch_val_accuracy:.4f}\")\n",
        "\n",
        "# Save the model\n",
        "PATH = f\"epochs_{epochs}img{IMG_SIZE}patch{patch_size}lr{lr}.pt\"\n",
        "torch.save(model.state_dict(), PATH)\n",
        "\n",
        "# Load saved model\n",
        "efficient_transformer = Linformer(dim=128, seq_len=(IMG_SIZE // patch_size) ** 2 + 1, depth=12, heads=8, k=64)\n",
        "model = ViT(image_size=IMG_SIZE, patch_size=patch_size, num_classes=num_classes, dim=128, transformer=efficient_transformer, channels=3).to(device)\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Function to calculate overall accuracy\n",
        "def overall_accuracy(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    y_proba = []\n",
        "    y_truth = []\n",
        "    test_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, label in tqdm(test_loader):\n",
        "            data, label = data.to(device), label.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, label.long()).item()\n",
        "            for index, i in enumerate(output):\n",
        "                y_proba.append(i[1].item())\n",
        "                y_truth.append(label[index].item())\n",
        "                if torch.argmax(i) == label[index]:\n",
        "                    correct += 1\n",
        "                total += 1\n",
        "    accuracy = correct / total\n",
        "    y_proba_out = np.array(y_proba)\n",
        "    y_truth_out = np.array(y_truth)\n",
        "    return test_loss, accuracy, y_proba_out, y_truth_out\n",
        "\n",
        "# Evaluate model on test data\n",
        "loss, acc, y_proba, y_truth = overall_accuracy(model, test_loader, criterion)\n",
        "\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Plot confusion matrix\n",
        "cm = confusion_matrix(y_truth, np.argmax(y_proba.reshape(-1, 1), axis=1))\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIaM0gpmLwqh",
        "outputId": "dd936ab0-ff8f-48b2-8dd2-7fb40a66b04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 10/37 [01:51<04:41, 10.42s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NzAlpx3qLwtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NxUuy-dGLwvl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}